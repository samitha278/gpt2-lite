{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNqcg8lh8z9Fpc+IF4MkDq+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samitha278/gpt2-lite/blob/main/complete_gpt2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "s-k5lDK9R2DF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import gdown\n",
        "import tiktoken\n",
        "\n",
        "from dataclasses import dataclass\n",
        "\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data file doenload\n",
        "\n",
        "file_id = \"1ia6z4itw7WJWpnoTohURX6Lm-AnZmVZz\"\n",
        "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "\n",
        "output = \"input.txt\"\n",
        "gdown.download(url, output, quiet=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "RAs1hsQlVHxZ",
        "outputId": "dc73c80f-cb0f-4fe4-ea5c-aae597709cf8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ia6z4itw7WJWpnoTohURX6Lm-AnZmVZz\n",
            "To: /content/input.txt\n",
            "100%|██████████| 1.12M/1.12M [00:00<00:00, 81.5MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'input.txt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPT-2 Model"
      ],
      "metadata": {
        "id": "N2Og5-0LTdM5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class GPT2Config:\n",
        "    block_size : int = 1024\n",
        "    vocab_size : int = 50257\n",
        "    n_layer : int = 12\n",
        "    n_head : int = 12\n",
        "    n_embd : int = 768"
      ],
      "metadata": {
        "id": "ZmTrswygUKfi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPT2(nn.Module):\n",
        "\n",
        "    def __init__(self,config):\n",
        "        super().__init__()\n",
        "\n",
        "        self.config = config\n",
        "\n",
        "        self.transformer = nn.ModuleDict(dict(\n",
        "            wte = nn.Embedding(config.vocab_size,config.n_embd),\n",
        "            wpe = nn.Embedding(config.block_size,config.n_embd),\n",
        "\n",
        "            h = nn.ModuleList([Block(config) for i in range(config.n_layer)]),\n",
        "\n",
        "            ln_f = nn.LayerNorm(config.n_embd),\n",
        "\n",
        "        ))\n",
        "\n",
        "        self.lm_head = nn.Linear(config.n_embd,config.vocab_size, bias=False)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self,x,targets= None):\n",
        "\n",
        "        B,T = x.shape\n",
        "        assert T<= self.config.block_size   # positional embd table max size = block_size\n",
        "        tx = self.transformer.wte(x)       #token embedding\n",
        "        px = self.transformer.wpe(torch.arange(0,T,self.config.block_size,device=device)) #positional embedding\n",
        "\n",
        "        x = tx+px     # add both\n",
        "\n",
        "        for block in self.transformer.h:\n",
        "          x = block(x)\n",
        "\n",
        "        x = self.transformer.ln_f(x)\n",
        "\n",
        "        logits = self.lm_head(x)\n",
        "\n",
        "        if targets is None:\n",
        "            return logits\n",
        "        else:\n",
        "            loss = F.cross_entropy(logits.view(B*T,-1) ,targets.view(-1))\n",
        "            return logits,loss\n",
        "\n",
        "\n",
        "\n",
        "    @classmethod\n",
        "    def from_pretrained(cls, model_type='gpt2'):\n",
        "        from transformers import GPT2LMHeadModel\n",
        "        assert model_type == 'gpt2'\n",
        "\n",
        "        config_args = dict(n_layer=12, n_head=12, n_embd=768, vocab_size=50257, block_size=1024)\n",
        "        config = GPT2Config(**config_args)\n",
        "        model = GPT2(config)\n",
        "\n",
        "        sd = model.state_dict()\n",
        "        sd_keys = [k for k in sd.keys() if not k.endswith('.attn.bias')]\n",
        "\n",
        "        model_hf = GPT2LMHeadModel.from_pretrained(model_type)\n",
        "        sd_hf = model_hf.state_dict()\n",
        "        sd_keys_hf = [k for k in sd_hf.keys() if not k.endswith(('.attn.masked_bias', '.attn.bias'))]\n",
        "\n",
        "        transposed = ['attn.c_attn.weight', 'attn.c_proj.weight', 'mlp.c_fc.weight', 'mlp.c_proj.weight']\n",
        "        assert len(sd_keys_hf) == len(sd_keys)\n",
        "\n",
        "        for k in sd_keys_hf:\n",
        "            if any(k.endswith(w) for w in transposed):\n",
        "                assert sd_hf[k].shape[::-1] == sd[k].shape\n",
        "                with torch.no_grad():\n",
        "                    sd[k].copy_(sd_hf[k].t())\n",
        "            else:\n",
        "                assert sd_hf[k].shape == sd[k].shape\n",
        "                with torch.no_grad():\n",
        "                    sd[k].copy_(sd_hf[k])\n",
        "\n",
        "        return model\n",
        "\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------------------------------\n",
        "\n",
        "class Block(nn.Module):\n",
        "\n",
        "    def __init__(self,config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.ln_1 = nn.LayerNorm(config.n_embd)\n",
        "        self.attn = SelfAttention(config)\n",
        "        self.ln_2 = nn.LayerNorm(config.n_embd)\n",
        "        self.mlp = MLP(config)\n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        x = self.attn(self.ln_1(x)) + x\n",
        "        x = self.mlp(self.ln_2(x)) + x\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "    def __init__(self,config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.c_fc = nn.Linear(config.n_embd,4*config.n_embd)\n",
        "        self.gelu = nn.GELU()\n",
        "        self.c_proj = nn.Linear(4*config.n_embd,config.n_embd)\n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.c_fc(x)\n",
        "        x = self.gelu(x)\n",
        "        x = self.c_proj(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# ----------------------------------------------------------------------------------\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "\n",
        "        block_size = config.block_size\n",
        "\n",
        "        self.n_head = n_head = config.n_head\n",
        "        self.n_embd = n_embd = config.n_embd\n",
        "\n",
        "\n",
        "        assert n_embd % n_head == 0\n",
        "        self.head_size = n_embd // n_head\n",
        "\n",
        "        self.c_attn = nn.Linear(n_embd, 3 * n_embd)     # fan out : n_head * 3 * head_size\n",
        "\n",
        "        self.c_proj = nn.Linear(n_embd, n_embd)\n",
        "\n",
        "        self.register_buffer(\"bias\", torch.tril(torch.ones(block_size, block_size,device = device)))\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.size()  # C = n_embd = n_head * head_size\n",
        "\n",
        "        qkv = self.c_attn(x)    # B,T, 3*n_embd\n",
        "\n",
        "        q, k, v = qkv.split(self.n_embd, dim=2)    # each : B,T, n_head * head_size\n",
        "\n",
        "        k = k.view(B, T, self.n_head, self.head_size).transpose(1, 2)    # B, n_head, T, head_size\n",
        "        q = q.view(B, T, self.n_head, self.head_size).transpose(1, 2)    # \"\"\n",
        "        v = v.view(B, T, self.n_head, self.head_size).transpose(1, 2)    # \"\"\n",
        "\n",
        "        att = (q @ k.transpose(-2, -1)) * (self.head_size**-0.5)         # B, n_head, T, T\n",
        "        att = att.masked_fill(self.bias[:T,:T] == 0, float('-inf'))\n",
        "        att = F.softmax(att, dim=-1)\n",
        "\n",
        "        y = att @ v        # B, n_head, T, head_size\n",
        "        y = y.transpose(1, 2).contiguous().view(B, T, C)   # B, T , n_embd   (n_embd = n_head * head_size)\n",
        "\n",
        "        y = self.c_proj(y)\n",
        "        return y\n",
        ""
      ],
      "metadata": {
        "id": "we2k_2CzTNUn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "aMtzc4ZoT1-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_iter = 50 # 10000\n",
        "lr = 3e-4\n",
        "\n",
        "\n",
        "\n",
        "#------------------------------------------------------------------\n",
        "\n",
        "#Initialize model\n",
        "\n",
        "config = GPT2Config()\n",
        "\n",
        "gpt2_model = GPT2(config)\n",
        "gpt2_model = gpt2_model.to(device)\n",
        "\n",
        "\n",
        "#------------------------------------------------------------------\n",
        "\n",
        "\n",
        "#text read\n",
        "with open('input.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "#get encoder\n",
        "enc = tiktoken.get_encoding('gpt2')\n",
        "\n",
        "\n",
        "#prepare data to train\n",
        "data = text[:1000]\n",
        "tokens = enc.encode(data)    #encoding\n",
        "\n",
        "\n",
        "#Just one batch\n",
        "\n",
        "B,T = 4,8\n",
        "temp = torch.tensor(tokens[:B*T+1])\n",
        "temp.to(device)\n",
        "xb = temp[:-1].view(B,T)\n",
        "yb = temp[1:].view(B,T)\n",
        "xb = xb.to(device)\n",
        "yb = yb.to(device)\n",
        "\n",
        "#------------------------------------------------------------------\n",
        "\n",
        "#Train\n",
        "losses = torch.zeros((max_iter,))\n",
        "\n",
        "\n",
        "optimizer = torch.optim.AdamW(gpt2_model.parameters(),lr=lr)\n",
        "\n",
        "for i in range(max_iter):\n",
        "\n",
        "    # xb,yb = get_batch('train')\n",
        "\n",
        "    logits , loss = gpt2_model(xb,yb)\n",
        "\n",
        "    #train\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "\n",
        "    losses[i] = loss.item()   # store losses\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(losses[-1])\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7sOl1BOTt56",
        "outputId": "7e09476b-7c1d-41b5-bdac-ab46a83a8f23"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.1064)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot losses just for one single batch\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(4,3))\n",
        "plt.plot(losses)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "id": "wbVy2fEuU9KU",
        "outputId": "577cf4fb-7cca-4de2-e3e9-fb15feaf18c8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jt1uAEPdWPB_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}